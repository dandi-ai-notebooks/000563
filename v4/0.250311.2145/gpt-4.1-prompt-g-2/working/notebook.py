# %% [markdown]
# # Exploring Dandiset 000563: Allen Institute Openscope – Barcoding (Version 0.250311.2145)
#
# **Caution:**  
# This notebook was generated by AI and has not been verified by a human expert. Users should exercise caution in interpreting results or reusing code—please carefully check all critical steps for your application.
#
# ## Dandiset Overview
#
# - **Name:** Allen Institute Openscope - Barcoding
# - **Description:**  
#   Visual neuroscience data recorded using high-density Neuropixels probes in mouse cortex and subcortical regions. The experiment employs white noise visual stimulation in both full-field and grating formats to drive temporally precise ("barcoding") activity patterns in visual and downstream brain areas. Key subject details: male, transgenic mouse, Pvalb-IRES-Cre background.
# - **Keywords:** mouse, neuropixel, extracellular electrophysiology, neocortex, inhibitory/excitatory, barcoding, temporal precision  
# - **Number of files:** 94 (across subjects, sessions, and probe recordings)
#
# [View this Dandiset on DANDI Archive](https://dandiarchive.org/dandiset/000563/0.250311.2145)
#
# ## What this notebook covers
#
# - How to load Dandiset metadata using the DANDI API
# - How to stream and inspect an example NWB file (electrophysiology/LFP)
# - Detailed illustration of LFP data structure, channel metadata, and visualization
# - Summary of provided variables and how to proceed with further exploration
#
# ---
# ### Required packages
#
# You will need:  
# `pynwb`, `remfile`, `h5py`, `pandas`, `numpy`, `matplotlib`
# (all are assumed to be pre-installed)
#
# ---
# %% [markdown]
# ## 1. Load and Explore Dandiset Metadata

# %%
from itertools import islice
from dandi.dandiapi import DandiAPIClient

# Connect to DANDI archive
client = DandiAPIClient()
dandiset = client.get_dandiset("000563", "0.250311.2145")

# Print basic information about the Dandiset
metadata = dandiset.get_raw_metadata()
print(f"Dandiset name: {metadata['name']}")
print(f"Dandiset URL: {metadata['url']}")

# List some assets in the Dandiset
assets = dandiset.get_assets()
print("\nFirst 5 assets:")
for asset in islice(assets, 5):
    print(f"- {asset.path} (ID: {asset.identifier})")

# %% [markdown]
# ## 2. Example NWB File: sub-681446_ses-1290510496_probe-0_ecephys.nwb
#
# We'll illustrate analysis using:  
# `sub-681446/sub-681446_ses-1290510496_probe-0_ecephys.nwb`  
# *[Asset ID: 1f158fe0-f8ef-495e-b031-da25316a335c]*
#
# - [File on DANDI](https://dandiarchive.org/dandiset/000563/0.250311.2145/files?path=sub-681446%2Fsub-681446_ses-1290510496_probe-0_ecephys.nwb)
# - [File on NeuroSift](https://neurosift.app/nwb?url=https://api.dandiarchive.org/api/assets/1f158fe0-f8ef-495e-b031-da25316a335c/download/&dandisetId=000563&dandisetVersion=draft)
#
# *Below, we stream this file directly from the archive without full download.*

# %%
import pynwb
import h5py
import remfile

file_url = "https://api.dandiarchive.org/api/assets/1f158fe0-f8ef-495e-b031-da25316a335c/download/"
remote_file = remfile.File(file_url)
h5_file = h5py.File(remote_file)
io = pynwb.NWBHDF5IO(file=h5_file)
nwb = io.read()

print(f"Session: {nwb.session_description}")
print(f"Subject: {nwb.subject.specimen_name}, Sex: {nwb.subject.sex}, Genotype: {nwb.subject.genotype}")
print(f"Session start: {nwb.session_start_time}")
print(f"Institution: {getattr(nwb, 'institution', '')}")
print(f"Available acquisitions: {list(nwb.acquisition.keys())}")

# %% [markdown]
# ## NWB Structure and Channel Summary
#
# The LFP data is contained in `nwb.acquisition['probe_0_lfp'].electrical_series['probe_0_lfp_data']`.  
# Info:
# - **Data shape:** (10168076, 73) — over 10 million timepoints, 73 LFP channels
# - **Unit:** Volts
# - **LFP sample rate:** 625 Hz (meta); raw probe sample rate: 30,000 Hz
#
# **Electrode regions:** Example breakdown by region:
#
# | Brain Region | Channel Count |
# |--------------|:------------:|
# | CA1          | 19           |
# | VISam5       | 9            |
# | VISam2/3     | 8            |
# | DG-mo        | 7            |
# | LP           | 7            |
# | APN          | 5            |
# | VISam6a      | 5            |
# | root         | 4            |
# | DG-sg        | 3            |
# | VISam1       | 3            |
# | ...          | ...          |
#
# *Below, we show how to load the electrode metadata as a DataFrame for further inspection.*
# Let's also visualize the distribution of electrodes by brain region.

# %%
import pandas as pd
import matplotlib.pyplot as plt

elec_tbl = nwb.electrodes
elec_df = elec_tbl.to_dataframe()
print("Electrode table columns:")
print(list(elec_df.columns))
print("First 5 rows:")
print(elec_df.head())

# Bar plot: number of electrodes per brain region
plt.figure(figsize=(8, 4))
region_counts = elec_df["location"].value_counts()
region_counts.plot(kind="bar")
plt.title("Electrode count per brain region")
plt.ylabel("Electrodes")
plt.xlabel("Brain region")
plt.tight_layout()
plt.show()

# %% [markdown]
# ## 3. LFP Preview: Visualizing Example Traces
#
# Here we plot the first 5 seconds of LFP from 5 example channels (evenly spaced from the 73 available).
# Channel selection is for illustrative purposes; flat lines may indicate low signal or dead channels.

# %%
import numpy as np
import matplotlib.pyplot as plt

sample_rate = 625
n_seconds = 5
n_samples = n_seconds * sample_rate
n_channels = elec_df.shape[0]
# Select 5 evenly spaced channels (spread throughout probe for anatomical diversity)
channels_to_plot = np.linspace(0, n_channels - 1, 5, dtype=int)
data = np.array(nwb.acquisition['probe_0_lfp'].electrical_series['probe_0_lfp_data'].data[:n_samples, channels_to_plot])
t = np.arange(n_samples) / sample_rate

plt.figure(figsize=(10, 6))
for i, ch in enumerate(channels_to_plot):
    plt.plot(t, data[:, i] * 1e3 + i * 2, label=f"Ch {ch} ({elec_df.iloc[ch]['location']})")  # mV and offset
plt.xlabel("Time (s)")
plt.ylabel("LFP (mV, offset for visibility)")
plt.title("Example LFP traces (first 5 seconds, 5 channels)")
plt.legend()
plt.tight_layout()
plt.show()

# %% [markdown]
# ## 3b. LFP Heatmap: Mean LFP Value per Channel (Preview Segment)
#
# Here we visualize the mean LFP in the 5-second preview window for each channel as a simple heatmap. Note that actual mapping to probe geometry would require additional metadata.

# %%
lfp_data_fullchan = np.array(nwb.acquisition['probe_0_lfp'].electrical_series['probe_0_lfp_data'].data[:n_samples, :])
mean_vals = lfp_data_fullchan.mean(axis=0)
plt.figure(figsize=(10,2))
plt.imshow(mean_vals[None, :], aspect="auto", cmap="viridis")
plt.yticks([])
plt.xlabel("Channel")
plt.title("Mean LFP per channel (first 5s segment)")
plt.colorbar(label="Mean voltage (V)")
plt.show()

# %% [markdown]
# ## 3c. Spectrogram (Time-Frequency Analysis) of a Sample Channel
#
# Power spectra are widely used to inspect neural oscillations. Below is a basic spectrogram for channel 0, preview segment.

# %%
from scipy.signal import spectrogram

ch_idx = 0
f, t_spec, Sxx = spectrogram(lfp_data_fullchan[:, ch_idx], fs=sample_rate, nperseg=256)
plt.figure(figsize=(10, 3))
plt.pcolormesh(t_spec, f, Sxx, shading="auto")
plt.ylabel('Frequency [Hz]')
plt.xlabel('Time [s]')
plt.title('Spectrogram (channel 0, preview segment)')
plt.colorbar(label="Power")
plt.tight_layout()
plt.show()

# %% [markdown]
# ## 4. Summary and Future Directions
#
# This notebook demonstrated:
# - Loading and summarizing Dandiset metadata and asset structure
# - Streaming NWB neurophysiology files and interpreting their structure
# - Inspecting and visualizing LFP data with trace, heatmap, and spectral approaches
# - Examining anatomical/region-associated channel metadata
#
# **Potential Next Steps**:
# - Explore spikes/unit tables (if present) and their relation to LFP and stimulus events
# - Analyze time-locked responses to visual stimuli (see stimulus_timestamps/notes where available)
# - Extend anatomical mapping using full 3D probe/channel metadata
# - Run more in-depth frequency or region-specific analyses, or connect data with the "barcoding" identification hypothesis described in the Dandiset
#
# **Note:** Some advanced analyses may be limited by streaming speed and dataset complexity in this AI-generated example.
#
# **Reminder:** This notebook was generated by an AI and should be carefully reviewed for correctness. The code and examples may require adaptation for other files or deeper scientific questions.