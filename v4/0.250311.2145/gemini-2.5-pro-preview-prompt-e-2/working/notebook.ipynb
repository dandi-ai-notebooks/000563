{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5007660",
   "metadata": {},
   "source": [
    "# Exploring Dandiset 000563: Allen Institute Openscope - Barcoding (Version 0.250311.2145)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8442595",
   "metadata": {},
   "source": [
    "**Important Note:** This notebook was AI-generated and has not been fully verified. Please be cautious when interpreting the code or results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8daf10c",
   "metadata": {},
   "source": [
    "## Overview of the Dandiset\n",
    "\n",
    "This Dandiset, titled \"Allen Institute Openscope - Barcoding,\" contains data related to how visual neurons respond to white noise flicker visual stimuli. The experiments used the OpenScope Neuropixels passive viewing protocol with mice. The visual stimuli were either a spatially uniform field whose luminance was modulated in time (Full Field Flicker) or a standing sinusoidal grating whose contrast was modulated in time (Static Gratings). The dataset aims to provide \"barcodes\" for visually responsive neurons throughout the mouse brain, which could potentially be used as identifiers of discrete cell types.\n",
    "\n",
    "You can find more information about this Dandiset and access its data at:\n",
    "[https://dandiarchive.org/dandiset/000563/0.250311.2145](https://dandiarchive.org/dandiset/000563/0.250311.2145)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a29792",
   "metadata": {},
   "source": [
    "## Purpose of this Notebook\n",
    "\n",
    "This notebook will guide you through:\n",
    "1. Listing the required Python packages.\n",
    "2. Connecting to the DANDI archive and retrieving basic information about the Dandiset.\n",
    "3. Listing some of the assets (files) available in the Dandiset.\n",
    "4. Loading a specific NWB (Neurodata Without Borders) file from the Dandiset.\n",
    "5. Exploring the metadata and contents of the loaded NWB file.\n",
    "6. Visualizing some example data from the NWB file, such as eye tracking and running speed.\n",
    "7. Summarizing the findings and suggesting potential future directions for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f20a75",
   "metadata": {},
   "source": [
    "## Required Packages\n",
    "\n",
    "To run this notebook, you will need the following Python packages. Please ensure they are installed in your environment.\n",
    "\n",
    "- `dandi` (for interacting with the DANDI Archive)\n",
    "- `pynwb` (for reading NWB files)\n",
    "- `h5py` (dependency for pynwb, for HDF5 file access)\n",
    "- `remfile` (for streaming remote files)\n",
    "- `numpy` (for numerical operations)\n",
    "- `matplotlib` (for plotting)\n",
    "- `seaborn` (for enhanced visualizations)\n",
    "- `pandas` (for data manipulation, especially with NWB tables)\n",
    "\n",
    "This notebook assumes these packages are already installed. No `pip install` commands are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94124359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from itertools import islice\n",
    "from dandi.dandiapi import DandiAPIClient\n",
    "import pynwb\n",
    "import h5py\n",
    "import remfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Apply a seaborn style for plots\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1d870c",
   "metadata": {},
   "source": [
    "## Connecting to DANDI and Loading Dandiset Information\n",
    "\n",
    "We will use the `DandiAPIClient` to connect to the DANDI archive and retrieve information about our target Dandiset (000563, version 0.250311.2145)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869bee46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to DANDI archive\n",
    "client = DandiAPIClient()\n",
    "dandiset_id = \"000563\"\n",
    "dandiset_version = \"0.250311.2145\"\n",
    "dandiset = client.get_dandiset(dandiset_id, dandiset_version)\n",
    "\n",
    "# Print basic information about the Dandiset from its raw metadata\n",
    "metadata = dandiset.get_raw_metadata()\n",
    "print(f\"Dandiset name: {metadata.get('name', 'N/A')}\")\n",
    "print(f\"Dandiset URL: {metadata.get('url', 'N/A')}\")\n",
    "print(f\"Dandiset description: {metadata.get('description', 'N/A')[:500]}...\") # Print first 500 chars of description\n",
    "\n",
    "# List some assets in the Dandiset\n",
    "assets = dandiset.get_assets()\n",
    "print(\"\\nFirst 5 assets:\")\n",
    "for asset in islice(assets, 5):\n",
    "    print(f\"- {asset.path} (ID: {asset.identifier})\") # asset.identifier is correct for RemoteBlobAsset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc57c190",
   "metadata": {},
   "source": [
    "## Loading an NWB File\n",
    "\n",
    "Now, let's load one of the NWB files from this Dandiset. We will use the file `sub-681446/sub-681446_ses-1290510496_ogen.nwb`.\n",
    "The `tools_cli.py nwb-file-info` command (which is not run in this notebook) provides the direct download URL and Python code snippets for loading. We will use that information here.\n",
    "\n",
    "The asset ID for this file is `2f2ac304-83a3-4352-8612-5f34b68062a0`.\n",
    "The download URL is: `https://api.dandiarchive.org/api/assets/2f2ac304-83a3-4352-8612-5f34b68062a0/download/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d97739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the URL for the NWB file\n",
    "nwb_asset_id = \"2f2ac304-83a3-4352-8612-5f34b68062a0\"\n",
    "nwb_file_url = f\"https://api.dandiarchive.org/api/assets/{nwb_asset_id}/download/\"\n",
    "selected_file_path = \"sub-681446/sub-681446_ses-1290510496_ogen.nwb\" # For display purposes\n",
    "\n",
    "print(f\"Loading NWB file: {selected_file_path}\")\n",
    "print(f\"From URL: {nwb_file_url}\")\n",
    "\n",
    "# Load the NWB file using remfile and pynwb\n",
    "# This code is based on the output of `tools_cli.py nwb-file-info`\n",
    "remote_file_stream = remfile.File(nwb_file_url)\n",
    "h5_file = h5py.File(remote_file_stream, 'r') # Specify read-only mode\n",
    "io = pynwb.NWBHDF5IO(file=h5_file, mode='r') # Specify read-only mode for IO\n",
    "nwbfile = io.read()\n",
    "\n",
    "print(\"\\nNWB file loaded successfully.\")\n",
    "print(f\"Session ID: {nwbfile.session_id}\")\n",
    "print(f\"Session Start Time: {nwbfile.session_start_time}\")\n",
    "print(f\"Subject ID: {nwbfile.subject.subject_id if nwbfile.subject else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e25b0a4",
   "metadata": {},
   "source": [
    "### Neurosift Link for Interactive Exploration\n",
    "\n",
    "You can explore this NWB file interactively using Neurosift:\n",
    "[https://neurosift.app/nwb?url=https://api.dandiarchive.org/api/assets/2f2ac304-83a3-4352-8612-5f34b68062a0/download/&dandisetId=000563&dandisetVersion=0.250311.2145](https://neurosift.app/nwb?url=https://api.dandiarchive.org/api/assets/2f2ac304-83a3-4352-8612-5f34b68062a0/download/&dandisetId=000563&dandisetVersion=0.250311.2145)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822c06d0",
   "metadata": {},
   "source": [
    "## Exploring the NWB File Contents\n",
    "\n",
    "Let's look at some of the metadata and data containers within the loaded NWB file.\n",
    "The `nwb-file-info` tool output (not shown here) gives a detailed tree structure of the file. We will explore some common NWB components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74df1adc",
   "metadata": {},
   "source": [
    "### Acquisition Data\n",
    "\n",
    "The `nwbfile.acquisition` object often contains raw acquired data streams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9179414",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Contents of nwbfile.acquisition:\")\n",
    "if nwbfile.acquisition:\n",
    "    for item_name, item_data in nwbfile.acquisition.items():\n",
    "        print(f\"- {item_name}: ({type(item_data).__name__})\")\n",
    "        if hasattr(item_data, 'description'):\n",
    "            print(f\"  Description: {item_data.description}\")\n",
    "else:\n",
    "    print(\"No acquisition data found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe57155",
   "metadata": {},
   "source": [
    "Let's specifically look at `EyeTracking` data if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14058825",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"EyeTracking\" in nwbfile.acquisition:\n",
    "    eye_tracking_data = nwbfile.acquisition[\"EyeTracking\"]\n",
    "    print(\"\\nEyeTracking data details:\")\n",
    "    if hasattr(eye_tracking_data, 'spatial_series') and eye_tracking_data.spatial_series:\n",
    "        for series_name, series_obj in eye_tracking_data.spatial_series.items():\n",
    "            print(f\"  - {series_name} ({type(series_obj).__name__}):\")\n",
    "            if hasattr(series_obj, 'data'):\n",
    "                 print(f\"    Data shape: {series_obj.data.shape}, Data dtype: {series_obj.data.dtype}\")\n",
    "            if hasattr(series_obj, 'timestamps') and series_obj.timestamps is not None:\n",
    "                 print(f\"    Timestamps shape: {series_obj.timestamps.shape if hasattr(series_obj.timestamps, 'shape') else 'N/A (likely linked)'}\")\n",
    "    else:\n",
    "        print(\"  No spatial series found in EyeTracking.\")\n",
    "else:\n",
    "    print(\"\\nNo 'EyeTracking' data found in nwbfile.acquisition.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8c1cab",
   "metadata": {},
   "source": [
    "### Processing Modules\n",
    "\n",
    "The `nwbfile.processing` object often contains processed data derived from raw signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce83de3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nContents of nwbfile.processing:\")\n",
    "if nwbfile.processing:\n",
    "    for module_name, processing_module in nwbfile.processing.items():\n",
    "        print(f\"- {module_name}: ({type(processing_module).__name__}) - {processing_module.description}\")\n",
    "        if hasattr(processing_module, 'data_interfaces') and processing_module.data_interfaces:\n",
    "            print(\"  Data interfaces:\")\n",
    "            for di_name, di_obj in processing_module.data_interfaces.items():\n",
    "                print(f\"    - {di_name} ({type(di_obj).__name__})\")\n",
    "else:\n",
    "    print(\"No processing modules found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f92555",
   "metadata": {},
   "source": [
    "Let's look at `running` speed data from the `running` processing module, if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a65fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"running\" in nwbfile.processing and \"running_speed\" in nwbfile.processing[\"running\"].data_interfaces:\n",
    "    running_speed_ts = nwbfile.processing[\"running\"].data_interfaces[\"running_speed\"]\n",
    "    print(\"\\nRunning speed TimeSeries details:\")\n",
    "    print(f\"  Data shape: {running_speed_ts.data.shape}, Data dtype: {running_speed_ts.data.dtype}\")\n",
    "    print(f\"  Timestamps shape: {running_speed_ts.timestamps.shape}\")\n",
    "    print(f\"  Unit: {running_speed_ts.unit}\")\n",
    "else:\n",
    "    print(\"\\n'running_speed' TimeSeries not found in nwbfile.processing['running'].\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bf8dd8",
   "metadata": {},
   "source": [
    "### Intervals\n",
    "\n",
    "The `nwbfile.intervals` object can store information about epochs or experimental trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38b2351",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nContents of nwbfile.intervals:\")\n",
    "if nwbfile.intervals:\n",
    "    for interval_name, time_intervals in nwbfile.intervals.items():\n",
    "        print(f\"- {interval_name}: ({type(time_intervals).__name__}) - {time_intervals.description[:100]}...\")\n",
    "        print(f\"  Columns: {list(time_intervals.colnames)}\")\n",
    "        # Convert to DataFrame to see number of rows\n",
    "        df_interval = time_intervals.to_dataframe()\n",
    "        print(f\"  Number of intervals: {len(df_interval)}\")\n",
    "else:\n",
    "    print(\"No intervals found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb8bb28",
   "metadata": {},
   "source": [
    "### Units (Spike Data)\n",
    "\n",
    "The `nwbfile.units` table contains information about sorted spike units, if present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c2f494",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(\"\\nContents of nwbfile.units (spike data):\")\n",
    "if nwbfile.units:\n",
    "    print(f\"  Description: {nwbfile.units.description}\")\n",
    "    print(f\"  Columns: {list(nwbfile.units.colnames)}\")\n",
    "    # Convert to DataFrame to see number of units\n",
    "    df_units = nwbfile.units.to_dataframe()\n",
    "    print(f\"  Number of units: {len(df_units)}\")\n",
    "    if not df_units.empty:\n",
    "        print(\"\\n  Example of first few units (ID and quality):\")\n",
    "        print(df_units[['quality']].head()) # Showing only a few relevant columns for brevity\n",
    "else:\n",
    "    print(\"No units (spike data) found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d537f24b",
   "metadata": {},
   "source": [
    "## Visualizing Data from the NWB File\n",
    "\n",
    "Let's plot some of the data we've identified. We'll be careful to load only subsets of data if the full datasets are too large, to avoid long loading times over the network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a98439",
   "metadata": {},
   "source": [
    "### Visualizing Pupil Tracking Area\n",
    "\n",
    "If pupil tracking data is available under `nwbfile.acquisition['EyeTracking'].spatial_series['pupil_tracking']`, let's plot a segment of the pupil area over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53628217",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"EyeTracking\" in nwbfile.acquisition and \\\n",
    "   \"pupil_tracking\" in nwbfile.acquisition[\"EyeTracking\"].spatial_series:\n",
    "    pupil_tracking = nwbfile.acquisition[\"EyeTracking\"].spatial_series[\"pupil_tracking\"]\n",
    "\n",
    "    if hasattr(pupil_tracking, 'area') and hasattr(pupil_tracking, 'timestamps'):\n",
    "        print(\"Plotting pupil tracking area...\")\n",
    "        # Load a subset of data to keep it manageable\n",
    "        num_points_to_plot = 1000\n",
    "        pupil_area_data = pupil_tracking.area[:num_points_to_plot]\n",
    "        pupil_timestamps_data = pupil_tracking.timestamps[:num_points_to_plot]\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.set_theme() # Ensure seaborn theme is applied\n",
    "        plt.plot(pupil_timestamps_data, pupil_area_data)\n",
    "        plt.xlabel(f\"Time ({pupil_tracking.timestamps_unit})\")\n",
    "        plt.ylabel(f\"Pupil Area ({pupil_tracking.unit} relative)\") # Unit might be 'pixels' or relative\n",
    "        plt.title(f\"Pupil Area (First {num_points_to_plot} Points)\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Pupil tracking area or timestamps data not found.\")\n",
    "else:\n",
    "    print(\"Pupil tracking data ('EyeTracking' or 'pupil_tracking' series) not found in acquisition.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb5c7aa",
   "metadata": {},
   "source": [
    "### Visualizing Running Speed\n",
    "\n",
    "If running speed data is available under `nwbfile.processing['running'].data_interfaces['running_speed']`, let's plot a segment of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6954dc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"running\" in nwbfile.processing and \\\n",
    "   \"running_speed\" in nwbfile.processing[\"running\"].data_interfaces:\n",
    "    running_speed_ts = nwbfile.processing[\"running\"].data_interfaces[\"running_speed\"]\n",
    "\n",
    "    if hasattr(running_speed_ts, 'data') and hasattr(running_speed_ts, 'timestamps'):\n",
    "        print(\"Plotting running speed...\")\n",
    "        # Load a subset of data\n",
    "        num_points_to_plot = 2000\n",
    "        running_speed_data = running_speed_ts.data[:num_points_to_plot]\n",
    "        running_timestamps_data = running_speed_ts.timestamps[:num_points_to_plot]\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.set_theme() # Ensure seaborn theme is applied\n",
    "        plt.plot(running_timestamps_data, running_speed_data)\n",
    "        plt.xlabel(f\"Time ({running_speed_ts.timestamps_unit})\")\n",
    "        plt.ylabel(f\"Running Speed ({running_speed_ts.unit})\")\n",
    "        plt.title(f\"Running Speed (First {num_points_to_plot} Points)\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Running speed data or timestamps not found in the TimeSeries.\")\n",
    "else:\n",
    "    print(\"Running speed TimeSeries ('running_speed') not found in processing module 'running'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62258dc8",
   "metadata": {},
   "source": [
    "### Visualizing Spike Times from a Single Unit\n",
    "\n",
    "If spike data (`nwbfile.units`) is available, let's select the first unit and plot its spike times as a raster plot over a short interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801c278c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if nwbfile.units is not None and len(nwbfile.units.id) > 0:\n",
    "    print(\"Plotting spike times for the first unit...\")\n",
    "    units_df = nwbfile.units.to_dataframe()\n",
    "    \n",
    "    # Select the spike times for the first unit (index 0)\n",
    "    # The spike_times column in the DataFrame contains numpy arrays of spike times for each unit\n",
    "    first_unit_spike_times = units_df.iloc[0]['spike_times']\n",
    "    first_unit_id = units_df.index[0] # This gets the actual unit ID from the DataFrame index\n",
    "\n",
    "    if first_unit_spike_times is not None and len(first_unit_spike_times) > 0:\n",
    "        # Select a time window for plotting, e.g., the first 10 seconds of spikes\n",
    "        time_window_end = min(first_unit_spike_times[0] + 10, first_unit_spike_times[-1]) # Max 10s or end of recording\n",
    "        spikes_in_window = first_unit_spike_times[\n",
    "            (first_unit_spike_times >= first_unit_spike_times[0]) & (first_unit_spike_times <= time_window_end)\n",
    "        ]\n",
    "        \n",
    "        if len(spikes_in_window) > 0:\n",
    "            plt.figure(figsize=(12, 3))\n",
    "            sns.set_theme() # Ensure seaborn theme is applied\n",
    "            plt.eventplot(spikes_in_window, lineoffset=0, linelength=0.8)\n",
    "            plt.xlabel(\"Time (s)\")\n",
    "            plt.ylabel(f\"Unit ID: {first_unit_id}\")\n",
    "            plt.title(f\"Spike Raster for Unit {first_unit_id} (up to {time_window_end:.2f}s)\")\n",
    "            plt.yticks([]) # No y-ticks needed for a single unit raster\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(f\"Unit {first_unit_id} has no spikes in the selected initial window.\")\n",
    "    else:\n",
    "        print(f\"Unit {first_unit_id} has no spike times recorded or spike_times array is empty.\")\n",
    "else:\n",
    "    print(\"No units data found, or no units available to plot spike times.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391d019a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Summary and Future Directions\n",
    "\n",
    "This notebook demonstrated how to:\n",
    "- Connect to the DANDI archive and retrieve Dandiset metadata.\n",
    "- List assets within a Dandiset.\n",
    "- Load a specific NWB file using its DANDI asset URL.\n",
    "- Explore basic NWB file structure, including acquisition data, processing modules, intervals, and units.\n",
    "- Visualize example data such as pupil area, running speed, and spike times for a single unit.\n",
    "\n",
    "### Possible Future Directions for Analysis:\n",
    "\n",
    "1.  **Detailed Stimulus Correlation:** Explore the `nwbfile.intervals` (e.g., `RepeatFFF_presentations`, `UniqueFFF_presentations`, `static_block_presentations`) to correlate neural activity (spike times from `nwbfile.units`) with specific visual stimulus presentations.\n",
    "2.  **Population Analysis:** Analyze spike data from multiple units simultaneously. This could involve calculating population firing rates, cross-correlations, or applying dimensionality reduction techniques.\n",
    "3.  **Behavioral State Correlation:** Correlate neural activity with behavioral data, such as running speed or pupil metrics, to understand how brain state influences neural responses.\n",
    "4.  **Across-Animal/Across-Session Comparisons:** If other NWB files in this Dandiset follow a similar structure, the methods shown here can be adapted to compare data across different subjects or recording sessions.\n",
    "5.  **Advanced Visualizations:** Create more sophisticated visualizations, such as peristimulus time histograms (PSTHs) aligned to stimulus onsets, or heatmaps of neural activity across different conditions or trials.\n",
    "6.  **Explore other NWB files:** This notebook focused on an `_ogen.nwb` file. The Dandiset also contains `_ecephys.nwb` files which likely contain more detailed electrophysiology data (e.g., raw voltage traces, LFP), which could be explored similarly. Remember to always check the `nwb-file-info` output (externally) to understand the structure of those files first.\n",
    "\n",
    "Remember to consult the DANDI archive page for this Dandiset and any associated publications for more context on the experimental design and data collection, which will inform more targeted analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cacf91",
   "metadata": {},
   "source": [
    "---\n",
    "End of AI-Generated Notebook."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
