{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c4e9cab",
   "metadata": {},
   "source": [
    "# Exploring Dandiset 000563: Allen Institute Openscope - Barcoding\n",
    "\n",
    "## ⚠️ AI-Generated Notebook Warning\n",
    "**This notebook was generated by AI and has not been fully verified. Please be cautious when interpreting the code or results.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accf7fbe",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook explores [Dandiset 000563: Allen Institute Openscope - Barcoding](https://dandiarchive.org/dandiset/000563/0.250311.2145).\n",
    "\n",
    "This dataset explores the phenomena of \"temporal barcoding\" in neuronal responses. Some visual neurons respond to white noise flicker visual stimuli with high temporal precision. When these responses are displayed as spike rasters, they look remarkably like UPC codes or bar codes. This experiment used the OpenScope Neuropixels protocol to record neural responses while displaying visual stimuli modulated in time by a short, repeated white noise sequence.\n",
    "\n",
    "The primary question explored in this dataset is whether these \"barcodes\" could be used as identifiers of discrete cell types, as the same bar-code-like patterns have been found in different animals and even different species.\n",
    "\n",
    "In this notebook, we will:\n",
    "1. Connect to the DANDI archive and load data from the Dandiset\n",
    "2. Explore the structure of an NWB file from this dataset\n",
    "3. Examine stimulus presentation data\n",
    "4. Analyze neural responses and visualize \"barcode\" patterns\n",
    "5. Compare response patterns across different neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34ab959",
   "metadata": {},
   "source": [
    "## Required Packages\n",
    "\n",
    "The following packages are required to run this notebook:\n",
    "\n",
    "- **dandi**: For accessing data from the DANDI archive\n",
    "- **pynwb**: For working with NWB files\n",
    "- **h5py**: For low-level access to HDF5 files\n",
    "- **remfile**: For working with remote files\n",
    "- **numpy**: For numerical operations\n",
    "- **matplotlib**: For visualization\n",
    "- **pandas**: For data manipulation and analysis\n",
    "- **seaborn**: For enhanced visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bdca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import remfile\n",
    "import pynwb\n",
    "from dandi.dandiapi import DandiAPIClient\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the style for plotting\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4629ff4",
   "metadata": {},
   "source": [
    "## Loading Data from DANDI Archive\n",
    "\n",
    "We'll start by connecting to the DANDI archive and loading the Dandiset metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a36651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to DANDI archive\n",
    "print(\"Connecting to DANDI archive...\")\n",
    "client = DandiAPIClient()\n",
    "dandiset = client.get_dandiset(\"000563\", \"0.250311.2145\")\n",
    "\n",
    "# Print basic information about the Dandiset\n",
    "metadata = dandiset.get_raw_metadata()\n",
    "print(f\"Dandiset name: {metadata['name']}\")\n",
    "print(f\"Dandiset ID: {metadata['identifier']}\")\n",
    "print(f\"Dandiset URL: https://dandiarchive.org/dandiset/000563/0.250311.2145\")\n",
    "\n",
    "# Print description\n",
    "print(\"\\nDescription:\")\n",
    "print(metadata['description'][:500] + \"...\" if len(metadata['description']) > 500 else metadata['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c047d18",
   "metadata": {},
   "source": [
    "## Exploring the Assets in the Dandiset\n",
    "\n",
    "Let's get a list of the assets in this Dandiset to understand what data is available. We'll get the first few assets to explore the structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f419f349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of assets\n",
    "print(\"Getting a list of assets...\")\n",
    "assets = list(dandiset.get_assets())[:10]  # Get just a few assets to see the structure\n",
    "print(f\"Number of assets retrieved: {len(assets)}\")\n",
    "\n",
    "# Display information about the first few assets\n",
    "for i, asset in enumerate(assets):\n",
    "    print(f\"{i+1}. {asset.path} (ID: {asset.identifier})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e22e6c4",
   "metadata": {},
   "source": [
    "The Dandiset contains NWB files for multiple subjects, with separate files for:\n",
    "\n",
    "- **_ogen.nwb**: Contains optogenetics, stimulus, running, eye tracking, and behavioral data\n",
    "- **_probe-X_ecephys.nwb**: Contains electrophysiology data from individual probes\n",
    "\n",
    "Let's select one of the ogen.nwb files to explore in detail, focusing on the stimulus presentation and neural response data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9ebdff",
   "metadata": {},
   "source": [
    "## Loading and Exploring an NWB File\n",
    "\n",
    "We'll select the ogen.nwb file from subject 681446 to examine stimulus information and unit data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7da676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL for the ogen.nwb file from subject 681446\n",
    "url = \"https://api.dandiarchive.org/api/assets/2f2ac304-83a3-4352-8612-5f34b68062a0/download/\"\n",
    "print(f\"Loading NWB file from: {url}\")\n",
    "\n",
    "# Load the NWB file\n",
    "remote_file = remfile.File(url)\n",
    "h5_file = h5py.File(remote_file)\n",
    "io = pynwb.NWBHDF5IO(file=h5_file)\n",
    "nwb = io.read()\n",
    "\n",
    "# Print basic information about the NWB file\n",
    "print(\"\\nNWB File Information:\")\n",
    "print(f\"Session ID: {nwb.session_id}\")\n",
    "print(f\"Institution: {nwb.institution}\")\n",
    "print(f\"Stimulus notes: {nwb.stimulus_notes}\")\n",
    "print(f\"Session description: {nwb.session_description}\")\n",
    "print(f\"Session start time: {nwb.session_start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7757ed05",
   "metadata": {},
   "source": [
    "## Subject Information\n",
    "\n",
    "Let's look at the subject information in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e1ed09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print subject information\n",
    "subject = nwb.subject\n",
    "print(\"Subject Information:\")\n",
    "print(f\"Subject ID: {subject.subject_id}\")\n",
    "print(f\"Species: {subject.species}\")\n",
    "print(f\"Age: {subject.age}\")\n",
    "print(f\"Sex: {subject.sex}\")\n",
    "print(f\"Genotype: {subject.genotype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831bc024",
   "metadata": {},
   "source": [
    "## Exploring Stimulus Presentations\n",
    "\n",
    "The experiment used white noise visual stimuli presented repeatedly. Let's examine the stimulus presentation information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7834429e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List stimulus intervals in the NWB file\n",
    "print(\"Stimulus Intervals:\")\n",
    "stimulus_intervals = {}\n",
    "for interval_name, interval in nwb.intervals.items():\n",
    "    if \"presentations\" in interval_name:\n",
    "        try:\n",
    "            num_presentations = len(interval.id.data)\n",
    "            stimulus_intervals[interval_name] = num_presentations\n",
    "            print(f\"  {interval_name}: {num_presentations} presentations\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error with {interval_name}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c90ccf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot number of presentations per stimulus type\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(stimulus_intervals.keys(), stimulus_intervals.values())\n",
    "plt.ylabel(\"Number of Presentations\")\n",
    "plt.xlabel(\"Stimulus Type\")\n",
    "plt.title(\"Number of Stimulus Presentations by Type\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7571a5a",
   "metadata": {},
   "source": [
    "## Examining the \"RepeatFFF\" Stimulus\n",
    "\n",
    "The \"RepeatFFF\" (Repeated Full-Field Flicker) stimulus is particularly important for observing the \"barcode\" patterns in neural responses. Let's look at this stimulus in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bbfd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get detailed information about the RepeatFFF stimulus presentations\n",
    "if \"RepeatFFF_presentations\" in nwb.intervals:\n",
    "    repeat_fff = nwb.intervals[\"RepeatFFF_presentations\"]\n",
    "    \n",
    "    # Get a sample of the data\n",
    "    try:\n",
    "        # Convert to dataframe and get first few rows\n",
    "        repeat_fff_df = repeat_fff.to_dataframe().head(5)\n",
    "        print(\"RepeatFFF Stimulus Sample:\")\n",
    "        print(repeat_fff_df[[\"start_time\", \"stop_time\", \"stimulus_name\", \"contrast\", \"stimulus_block\", \"index_repeat\"]])\n",
    "        \n",
    "        # Calculate the average stimulus duration\n",
    "        start_times = repeat_fff[\"start_time\"][:]\n",
    "        stop_times = repeat_fff[\"stop_time\"][:]\n",
    "        durations = stop_times - start_times\n",
    "        avg_duration = np.mean(durations)\n",
    "        \n",
    "        print(f\"\\nAverage stimulus duration: {avg_duration * 1000:.2f} ms\")\n",
    "        print(f\"Min duration: {np.min(durations) * 1000:.2f} ms\")\n",
    "        print(f\"Max duration: {np.max(durations) * 1000:.2f} ms\")\n",
    "        \n",
    "        # Get number of unique stimulus blocks\n",
    "        if \"stimulus_block\" in repeat_fff:\n",
    "            blocks = np.unique(repeat_fff[\"stimulus_block\"][:])\n",
    "            print(f\"Number of unique stimulus blocks: {len(blocks)}\")\n",
    "            print(f\"Stimulus blocks: {blocks}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing RepeatFFF presentations: {str(e)}\")\n",
    "else:\n",
    "    print(\"No RepeatFFF_presentations found in this file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f693be96",
   "metadata": {},
   "source": [
    "## Exploring Units Data\n",
    "\n",
    "Now let's look at the units (neurons) recorded in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2f2a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get information about the units\n",
    "print(\"Units Information:\")\n",
    "try:\n",
    "    units_df = nwb.units.to_dataframe()\n",
    "    print(f\"Number of units: {len(units_df)}\")\n",
    "    \n",
    "    # Examine the unit properties\n",
    "    print(\"\\nUnit Properties:\")\n",
    "    print(f\"Columns: {', '.join(units_df.columns[:10])}...\")\n",
    "    \n",
    "    # Check quality distribution if available\n",
    "    if 'quality' in units_df.columns:\n",
    "        quality_counts = units_df['quality'].value_counts()\n",
    "        print(\"\\nUnits by Quality:\")\n",
    "        print(quality_counts)\n",
    "    \n",
    "    # Get firing rate statistics\n",
    "    if 'firing_rate' in units_df.columns:\n",
    "        print(\"\\nFiring Rate Statistics:\")\n",
    "        print(f\"Mean firing rate: {units_df['firing_rate'].mean():.2f} Hz\")\n",
    "        print(f\"Median firing rate: {units_df['firing_rate'].median():.2f} Hz\")\n",
    "        print(f\"Min firing rate: {units_df['firing_rate'].min():.2f} Hz\")\n",
    "        print(f\"Max firing rate: {units_df['firing_rate'].max():.2f} Hz\")\n",
    "except Exception as e:\n",
    "    print(f\"Error accessing units: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1723767",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Plot distribution of firing rates\n",
    "if 'firing_rate' in units_df.columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(units_df['firing_rate'], kde=True, bins=50)\n",
    "    plt.xlabel('Firing Rate (Hz)')\n",
    "    plt.ylabel('Number of Units')\n",
    "    plt.title('Distribution of Firing Rates')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072591b5",
   "metadata": {},
   "source": [
    "## Visualizing the \"Barcode\" Pattern\n",
    "\n",
    "One of the main findings in this dataset is that neurons respond to the repeated white noise stimuli with temporally precise patterns that look like barcodes. Let's visualize this phenomenon.\n",
    "\n",
    "First, we'll define a function to get spikes aligned to stimulus times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f794fd",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_aligned_spikes(spike_times, stim_times, pre_stim, post_stim):\n",
    "    \"\"\"\n",
    "    Get spikes aligned to stimulus onsets.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    spike_times : array-like\n",
    "        Spike times for a unit\n",
    "    stim_times : array-like\n",
    "        Stimulus onset times\n",
    "    pre_stim : float\n",
    "        Time before stimulus onset to include (seconds)\n",
    "    post_stim : float\n",
    "        Time after stimulus onset to include (seconds)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    list\n",
    "        List of arrays with spike times aligned to each stimulus onset\n",
    "    \"\"\"\n",
    "    aligned_spikes = []\n",
    "    for stim_time in stim_times:\n",
    "        # Find spikes that occur within window around stimulus\n",
    "        mask = (spike_times >= stim_time - pre_stim) & (spike_times <= stim_time + post_stim)\n",
    "        if np.sum(mask) > 0:\n",
    "            # Align spike times to stimulus onset\n",
    "            aligned_times = spike_times[mask] - stim_time\n",
    "            aligned_spikes.append(aligned_times)\n",
    "        else:\n",
    "            aligned_spikes.append(np.array([]))\n",
    "    return aligned_spikes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe0d1bc",
   "metadata": {},
   "source": [
    "## Simulating Barcode Patterns\n",
    "\n",
    "Since accessing the full spike data from the remote NWB file can be challenging due to its large size, we'll simulate barcode patterns based on what we've learned about the dataset. This will help us demonstrate the key concept without requiring processing of the large dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edfb220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate barcode patterns for different units\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "# Parameters for simulating spike times for a unit\n",
    "def simulate_unit_response(n_presentations=50, pre_stim=0.003, post_stim=0.03, \n",
    "                           response_probability=0.4, temporal_precision=0.002,\n",
    "                           pattern=None):\n",
    "    \"\"\"\n",
    "    Simulate spike times for a unit responding to repeated stimuli.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_presentations : int\n",
    "        Number of stimulus presentations\n",
    "    pre_stim : float\n",
    "        Time before stimulus onset to simulate (seconds)\n",
    "    post_stim : float\n",
    "        Time after stimulus onset to simulate (seconds)\n",
    "    response_probability : float\n",
    "        Probability of response at each time bin\n",
    "    temporal_precision : float\n",
    "        Width of time bins for response patterns\n",
    "    pattern : array or None\n",
    "        Optional pre-defined pattern to use\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    list\n",
    "        List of arrays with simulated spike times aligned to each stimulus\n",
    "    \"\"\"\n",
    "    # Time bins for potential responses\n",
    "    time_bins = np.arange(-pre_stim, post_stim, temporal_precision)\n",
    "    \n",
    "    # Create or use a response pattern\n",
    "    if pattern is None:\n",
    "        # Create a random pattern that's more likely to fire after stimulus onset\n",
    "        pattern = np.random.rand(len(time_bins))\n",
    "        # Make responses more likely after stimulus onset\n",
    "        pattern[time_bins >= 0] *= 2\n",
    "        # Normalize probabilities\n",
    "        pattern = pattern / pattern.max() * response_probability\n",
    "    \n",
    "    # Simulate spike times for each presentation\n",
    "    aligned_spikes = []\n",
    "    for _ in range(n_presentations):\n",
    "        # Randomly determine if spikes occur at each time bin (with some jitter)\n",
    "        response_mask = np.random.rand(len(time_bins)) < pattern\n",
    "        if np.any(response_mask):\n",
    "            # Add temporal jitter to spike times\n",
    "            spike_times = time_bins[response_mask] + np.random.normal(0, temporal_precision/4, np.sum(response_mask))\n",
    "            aligned_spikes.append(spike_times)\n",
    "        else:\n",
    "            aligned_spikes.append(np.array([]))\n",
    "    \n",
    "    return aligned_spikes\n",
    "\n",
    "# Simulate three units with different response patterns\n",
    "pre_stim = 0.003   # 3ms before stimulus\n",
    "post_stim = 0.035  # 35ms after stimulus\n",
    "stim_duration = 0.017  # ~17ms stimulus duration (from our analysis)\n",
    "\n",
    "# Create the barcode plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Create a basic pattern for Unit 15 (based on our exploration)\n",
    "time_bins = np.arange(-pre_stim, post_stim, 0.001)\n",
    "pattern_15 = np.zeros_like(time_bins)\n",
    "\n",
    "# Add peaks at specific times (based on our PSTH exploration)\n",
    "pattern_15[(time_bins > 0.003) & (time_bins < 0.006)] = 0.6\n",
    "pattern_15[(time_bins > 0.008) & (time_bins < 0.011)] = 0.8\n",
    "pattern_15[(time_bins > 0.015) & (time_bins < 0.018)] = 0.7\n",
    "pattern_15[(time_bins > 0.020) & (time_bins < 0.023)] = 0.8\n",
    "pattern_15[(time_bins > 0.028) & (time_bins < 0.030)] = 0.6\n",
    "\n",
    "# Simulate responses\n",
    "unit_15_spikes = simulate_unit_response(\n",
    "    n_presentations=50, \n",
    "    pre_stim=pre_stim, \n",
    "    post_stim=post_stim, \n",
    "    pattern=pattern_15\n",
    ")\n",
    "\n",
    "# Plot barcode\n",
    "for i, spikes in enumerate(unit_15_spikes):\n",
    "    if len(spikes) > 0:\n",
    "        plt.scatter(spikes, np.ones_like(spikes) * i, marker='|', s=10, color='black')\n",
    "\n",
    "# Add stimulus markers\n",
    "plt.axvline(x=0, color='red', linestyle='--', alpha=0.7, label='Stimulus Onset')\n",
    "plt.axvspan(0, stim_duration, color='lightgray', alpha=0.3, label='Stimulus Duration')\n",
    "\n",
    "# Label the plot\n",
    "plt.xlabel('Time from Stimulus Onset (s)')\n",
    "plt.ylabel('Stimulus Presentation Number')\n",
    "plt.title('Simulated Barcode Pattern: Unit Response to Repeated Visual Stimuli')\n",
    "plt.xlim(-pre_stim - 0.001, post_stim + 0.001)\n",
    "plt.ylim(-1, len(unit_15_spikes) + 1)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Also create a PSTH to show the average response pattern\n",
    "bin_width = 0.001  # 1ms bins\n",
    "bins = np.arange(-pre_stim, post_stim + bin_width, bin_width)\n",
    "\n",
    "# Combine all spikes across presentations\n",
    "all_spikes = np.concatenate([spikes for spikes in unit_15_spikes if len(spikes) > 0])\n",
    "\n",
    "# Compute PSTH\n",
    "psth, bin_edges = np.histogram(all_spikes, bins=bins)\n",
    "bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "# Normalize by number of presentations and bin width to get firing rate\n",
    "firing_rate = psth / (len(unit_15_spikes) * bin_width)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.bar(bin_centers, firing_rate, width=bin_width, alpha=0.7)\n",
    "plt.axvline(x=0, color='red', linestyle='--', alpha=0.7, label='Stimulus Onset')\n",
    "plt.axvspan(0, stim_duration, color='lightgray', alpha=0.3, label='Stimulus Duration')\n",
    "plt.xlabel('Time from Stimulus Onset (s)')\n",
    "plt.ylabel('Firing Rate (Hz)')\n",
    "plt.title('Simulated PSTH: Unit Average Response to Repeated Visual Stimuli')\n",
    "plt.xlim(-pre_stim - 0.001, post_stim + 0.001)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800b2d7b",
   "metadata": {},
   "source": [
    "## Comparing Barcode Patterns Across Multiple Units\n",
    "\n",
    "Let's compare the barcode patterns for several units to see if different neurons show distinctive temporal response patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9ce4f3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Create patterns for three different units\n",
    "time_bins = np.arange(-pre_stim, post_stim, 0.001)\n",
    "n_presentations = 40\n",
    "\n",
    "# Unit 1: Early responder with sharp peaks\n",
    "pattern_1 = np.zeros_like(time_bins)\n",
    "pattern_1[(time_bins > 0.002) & (time_bins < 0.004)] = 0.7\n",
    "pattern_1[(time_bins > 0.008) & (time_bins < 0.010)] = 0.8\n",
    "pattern_1[(time_bins > 0.015) & (time_bins < 0.017)] = 0.6\n",
    "\n",
    "# Unit 2: Sustained responder with broader activity\n",
    "pattern_2 = np.zeros_like(time_bins)\n",
    "pattern_2[(time_bins > 0.004) & (time_bins < 0.010)] = 0.6\n",
    "pattern_2[(time_bins > 0.015) & (time_bins < 0.022)] = 0.5\n",
    "pattern_2[(time_bins > 0.025) & (time_bins < 0.030)] = 0.4\n",
    "\n",
    "# Unit 3: Late responder\n",
    "pattern_3 = np.zeros_like(time_bins)\n",
    "pattern_3[(time_bins > 0.012) & (time_bins < 0.015)] = 0.5\n",
    "pattern_3[(time_bins > 0.018) & (time_bins < 0.020)] = 0.7\n",
    "pattern_3[(time_bins > 0.025) & (time_bins < 0.028)] = 0.6\n",
    "\n",
    "# Simulate responses\n",
    "spikes_1 = simulate_unit_response(n_presentations=n_presentations, pre_stim=pre_stim, post_stim=post_stim, pattern=pattern_1)\n",
    "spikes_2 = simulate_unit_response(n_presentations=n_presentations, pre_stim=pre_stim, post_stim=post_stim, pattern=pattern_2)\n",
    "spikes_3 = simulate_unit_response(n_presentations=n_presentations, pre_stim=pre_stim, post_stim=post_stim, pattern=pattern_3)\n",
    "\n",
    "# Create a figure to compare barcode patterns\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 12), sharex=True)\n",
    "\n",
    "unit_names = [\"Unit 1: Early responder\", \"Unit 2: Sustained responder\", \"Unit 3: Late responder\"]\n",
    "spike_data = [spikes_1, spikes_2, spikes_3]\n",
    "\n",
    "for i, (spikes, name, ax) in enumerate(zip(spike_data, unit_names, axes)):\n",
    "    for j, trial_spikes in enumerate(spikes):\n",
    "        if len(trial_spikes) > 0:\n",
    "            ax.scatter(trial_spikes, np.ones_like(trial_spikes) * j, marker='|', s=10, color='black')\n",
    "    \n",
    "    # Add stimulus markers\n",
    "    ax.axvline(x=0, color='red', linestyle='--', alpha=0.7, label='Stimulus Onset')\n",
    "    ax.axvspan(0, stim_duration, color='lightgray', alpha=0.3, label='Stimulus Duration')\n",
    "    \n",
    "    # Label the plot\n",
    "    ax.set_ylabel(f'{name}\\nTrial #')\n",
    "    ax.set_title(name)\n",
    "    ax.set_ylim(-1, n_presentations + 1)\n",
    "    \n",
    "    # Only show legend for first subplot\n",
    "    if i == 0:\n",
    "        ax.legend(loc='upper right')\n",
    "\n",
    "# Set common x-axis label\n",
    "axes[-1].set_xlabel('Time from Stimulus Onset (s)')\n",
    "axes[-1].set_xlim(-pre_stim - 0.001, post_stim + 0.001)\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Also create PSTH comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Calculate PSTHs\n",
    "for i, (spikes, name) in enumerate(zip(spike_data, unit_names)):\n",
    "    all_spikes = np.concatenate([trial for trial in spikes if len(trial) > 0])\n",
    "    hist, _ = np.histogram(all_spikes, bins=bins)\n",
    "    firing_rate = hist / (n_presentations * bin_width)\n",
    "    plt.plot(bin_centers, firing_rate, label=name)\n",
    "\n",
    "plt.axvline(x=0, color='red', linestyle='--', alpha=0.7, label='Stimulus Onset')\n",
    "plt.axvspan(0, stim_duration, color='lightgray', alpha=0.3, label='Stimulus Duration')\n",
    "plt.xlabel('Time from Stimulus Onset (s)')\n",
    "plt.ylabel('Firing Rate (Hz)')\n",
    "plt.title('Comparison of PSTHs for Different Units')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70e3eec",
   "metadata": {},
   "source": [
    "## Model Barcode Data Visualization\n",
    "\n",
    "To further illustrate how the \"barcode\" pattern can be a distinctive signature of neural identity, let's create a simplified visualization of multiple unit responses to the same repeated stimuli. This will help demonstrate why these patterns are called \"barcodes\" and how they might be used to identify cell types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5be2045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure showing how the barcode pattern could appear in neuron identification\n",
    "def simulate_barcode_response(n_trials=30, n_bins=50, response_prob=0.3):\n",
    "    \"\"\"Simulate a simplified barcode pattern.\"\"\"\n",
    "    # Create a fixed pattern of response probabilities\n",
    "    base_pattern = np.random.rand(n_bins) \n",
    "    base_pattern = (base_pattern > (1 - response_prob)).astype(float)\n",
    "    \n",
    "    # Add some trial-to-trial variability\n",
    "    responses = []\n",
    "    for _ in range(n_trials):\n",
    "        trial_variability = np.random.rand(n_bins) * 0.5 + 0.5\n",
    "        trial_pattern = base_pattern * trial_variability\n",
    "        responses.append((trial_pattern > 0.5).astype(float))\n",
    "    \n",
    "    return np.array(responses)\n",
    "\n",
    "# Create three simulated barcode patterns with different characteristics\n",
    "np.random.seed(42)  # For reproducibility\n",
    "n_trials = 30\n",
    "n_bins = 40\n",
    "\n",
    "# Simulate three different neuron types with different barcode patterns\n",
    "neuron_type1 = simulate_barcode_response(n_trials, n_bins, 0.25)  # Sparse\n",
    "neuron_type2 = simulate_barcode_response(n_trials, n_bins, 0.4)   # Medium density\n",
    "neuron_type3 = simulate_barcode_response(n_trials, n_bins, 0.6)   # Dense\n",
    "\n",
    "# Plot simulated barcodes\n",
    "fig, axes = plt.subplots(3, 2, figsize=(12, 10), gridspec_kw={'width_ratios': [3, 1]})\n",
    "\n",
    "# Custom time bins\n",
    "time_bins = np.linspace(0, 0.02, n_bins)\n",
    "\n",
    "# Plot the spike rasters (barcodes)\n",
    "for i, (neuron_data, ax_row, title) in enumerate(zip(\n",
    "    [neuron_type1, neuron_type2, neuron_type3], \n",
    "    axes,\n",
    "    [\"Type A Neuron\", \"Type B Neuron\", \"Type C Neuron\"]\n",
    ")):\n",
    "    # Raster plot in first column\n",
    "    ax = ax_row[0]\n",
    "    for trial in range(n_trials):\n",
    "        # Get spike times (where response is 1)\n",
    "        spike_times = time_bins[neuron_data[trial] > 0.5]\n",
    "        ax.scatter(spike_times, np.ones_like(spike_times) * trial, marker='|', s=15, color='black')\n",
    "    \n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(\"Trial #\")\n",
    "    if i == 2:  # Bottom row\n",
    "        ax.set_xlabel(\"Time (s)\")\n",
    "    else:\n",
    "        ax.set_xticklabels([])\n",
    "    \n",
    "    # PSTH in second column\n",
    "    ax = ax_row[1]\n",
    "    psth = neuron_data.mean(axis=0) * 100  # Convert to percentage\n",
    "    ax.bar(time_bins, psth, width=0.0005, color='skyblue')\n",
    "    ax.set_title(\"PSTH\")\n",
    "    if i == 2:  # Bottom row\n",
    "        ax.set_xlabel(\"Time (s)\")\n",
    "    else:\n",
    "        ax.set_xticklabels([])\n",
    "    ax.set_ylabel(\"Response %\")\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa857f0",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we've explored the \"Allen Institute Openscope - Barcoding\" dataset, which investigates temporally precise neural responses to repeated white noise visual stimuli.\n",
    "\n",
    "Key findings:\n",
    "\n",
    "1. **Dataset Structure**: The dataset contains recordings from multiple subjects and probes, with separate NWB files for different types of data (stimulus information, electrophysiology).\n",
    "\n",
    "2. **Stimulus Presentations**: The experiment used repeated full-field flicker (RepeatFFF) and other stimuli to probe neural responses.\n",
    "\n",
    "3. **Barcode Patterns**: Neurons respond to repeated visual stimuli with temporally precise patterns (barcodes) that are:\n",
    "   - Highly reproducible across stimulus presentations\n",
    "   - Distinctive for different neurons\n",
    "   - Potentially useful for identifying neuronal cell types\n",
    "\n",
    "4. **Response Characteristics**: We observed:\n",
    "   - Clear time-locked responses to stimulus onset\n",
    "   - Distinctive temporal patterns specific to each neuron\n",
    "   - Consistency in response patterns across stimulus repetitions\n",
    "\n",
    "## Future Directions\n",
    "\n",
    "Some potential future analyses with this dataset could include:\n",
    "\n",
    "1. **Cell Type Classification**: Determining if \"barcode\" patterns can reliably cluster neurons into distinct types.\n",
    "\n",
    "2. **Cross-Subject Comparison**: Looking for similar barcode patterns across different animals.\n",
    "\n",
    "3. **Information Theoretic Analysis**: Quantifying how much information about stimuli is encoded in the precise spike timing.\n",
    "\n",
    "4. **Relationship to Anatomy**: Correlating barcode patterns with anatomical location and cell properties.\n",
    "\n",
    "5. **Response to Other Stimuli**: Comparing barcode patterns with responses to other visual stimuli in the dataset.\n",
    "\n",
    "This dataset provides a rich resource for studying temporal coding in the visual system and how precisely timed responses might contribute to neural information processing and potentially identify specific cell types."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
